{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import csv\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "from time import time\n",
    "\n",
    "def timing(f):\n",
    "    @wraps(f)\n",
    "    def wrap(*args, **kw):\n",
    "        ts = time()\n",
    "        result = f(*args, **kw)\n",
    "        te = time()\n",
    "        print('func:%r args:[%r, %r] took: %2.4f sec' % \\\n",
    "          (f.__name__, args, kw, te-ts))\n",
    "        return result\n",
    "    return wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing\n",
    "def get_path():\n",
    "    '''\n",
    "    Let user select an initial (folder) path; or provide default PWD\n",
    "    '''\n",
    "    \n",
    "#    initial_path='C:\\\\Users\\\\Maarten\\\\Documents\\\\GitHub\\\\demo-databases'\n",
    "    print('Please enter path to folder where *.ipynb files can be found that need translation')\n",
    "    initial_path=input()\n",
    "    \n",
    "    attempts=0\n",
    "    \n",
    "    while os.path.exists(initial_path) == False: # or attempts <5:\n",
    "        print('Please enter path to folder where *.ipynb files can be found.')\n",
    "        initial_path=input()\n",
    "        attempts+=1\n",
    "        \n",
    "        if not os.path.exists(initial_path):\n",
    "            print('Invalid path provided. Please try again') \n",
    "        else: break\n",
    "\n",
    "        if attempts == 5:\n",
    "            print('To many attempts and invalid paths provided. Stopped.')\n",
    "            initial_path=''\n",
    "            break\n",
    "    \n",
    "    if initial_path == None:\n",
    "        initial_path = pwd()\n",
    "\n",
    "    return initial_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing\n",
    "def get_files(initial_path=''):\n",
    "    '''\n",
    "    Use a initial folder path to create a list of file paths.\n",
    "    \n",
    "    Filters file paths to resulst with only *.IPYNB files/extentions\n",
    "    \n",
    "    Keyword arguments:\n",
    "       initial_path : filename including extention (default: saved_file<datetime>.csv)\n",
    "    \n",
    "    Returns\n",
    "      filepaths : list of pathnames \n",
    "    '''\n",
    "      \n",
    "    base_dir=os.path.realpath(initial_path)+'\\\\'\n",
    "    filepaths=[]\n",
    "    \n",
    "    if os.path.isfile(initial_path):\n",
    "         if str(initial_path).find('.ipynb') > 0:\n",
    "            filepaths=[initial_path]\n",
    "    \n",
    "    elif os.path.isdir(initial_path):\n",
    "            if len(os.listdir(initial_path)) == 0:\n",
    "                print('No valid files found in {}.\\nStopped.\\n\\n'\\\n",
    "                      .format(str(initial_path)))\n",
    "            else:        \n",
    "                for file in os.listdir(initial_path):\n",
    "                    if str(file).find('.ipynb') > 0:\n",
    "                        filepaths.append(base_dir+file)\n",
    "    else: \n",
    "        print('No valid files found in {}.\\nStopped.\\n\\n'\\\n",
    "                      .format(str(initial_path)))\n",
    "    \n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing\n",
    "def create_json_data(filename):\n",
    "    \n",
    "    with open(filename, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "    \n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing\n",
    "def save_json_data(json_data, filename):\n",
    "    \n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(json_data, file, indent=2)\n",
    "    \n",
    "    return print('Saved json_data to file: {}'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing\n",
    "def process_json_data(json_data, search_words={}):\n",
    "    '''\n",
    "    Find and replace search_word values in a json object\n",
    "    \n",
    "    Keyword arguments:\n",
    "      json_data : json object\n",
    "      search_words : dict where key can be used to find a value in the values of the JSON object.\n",
    "                      Values in this dict contain the 'to replace with' values.\n",
    "                      \n",
    "    Example:\n",
    "      In order to translates Dutch 'onderdelen' to English 'parts'\n",
    "      \n",
    "      search_words = {'onderdelen':'parts'}\n",
    "      str.lower.replace('onderdelen' with 'parts') for a value in the a json_data['element']\n",
    "    \n",
    "    Returns\n",
    "      json_data : json object with updated values \n",
    "    '''\n",
    "    \n",
    "    for cell in json_data['cells']:\n",
    "\n",
    "         if cell['cell_type'] in ['code']:\n",
    "\n",
    "                for search_words_key in list(search_words.keys()):\n",
    "                    for val in cell['source']:\n",
    "                        if str.lower(val).find(str.lower(search_words_key)) >= 0:\n",
    "                            cell['source'][cell['source'].index(val)] = val.replace(search_words_key, search_words[search_words_key])\n",
    "\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_csv_to_dict(filename=''):\n",
    "    '''\n",
    "    Read CSV file (containing dict structured data) and create dict object.  \n",
    "    \n",
    "    Keyword arguments:\n",
    "      filename : filename including extention (default: '')\n",
    "    \n",
    "    Returns\n",
    "      dict_out : dictionary from CSV file content\n",
    "    '''\n",
    "    \n",
    "    dict_out={}\n",
    "    \n",
    "    with open(filename, mode='r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "#         with open('new_'+filename, mode='w') as outfile:\n",
    "#             writer = csv.writer(outfile)\n",
    "#             mydict = {rows[0]:rows[1] for rows in reader}\n",
    "        for row in reader:\n",
    "            for val in row:\n",
    "                key, value = val.split('|')\n",
    "                dict_out[key] = value\n",
    "    \n",
    "    infile.close()\n",
    "    \n",
    "    return dict_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing\n",
    "def check_filename(filename, file_extention=''):\n",
    "    '''\n",
    "    Check a filename (str) for several minimum requirements and \n",
    "       add the file_extention (str) w/o period character '.' to it.\n",
    "    \n",
    "    Keyword arguments:\n",
    "      filename : filename excluding extention (default: saved_file<datetime>)\n",
    "      file_extention : requested file extention (default: .csv)  \n",
    "    \n",
    "    Return filename (string)\n",
    "    '''\n",
    "\n",
    "    if type(filename) is not str:\n",
    "        filename=str(filename)\n",
    "    \n",
    "    if len(filename) == 0:\n",
    "        filename='saved_file'+datetime.now().strftime(\"%d-%b-%Y_%H-%M\").upper()\n",
    "    \n",
    "    if str(filename).find(file_extention)<0:\n",
    "        if str(file_extention).find('.')<0:\n",
    "            file_extention='.'+file_extention\n",
    "        if file_extention == '.' or len(file_extention)<4:\n",
    "            file_extention = '.csv'\n",
    "        filename=filename+file_extention\n",
    "    \n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing\n",
    "def save_list_to_csv(input_list=[], filename=''):\n",
    "    '''\n",
    "    Save a list object to an CSV file\n",
    "    \n",
    "    Keyword arguments:\n",
    "      input_list : list of values to write in .CSV file\n",
    "      filename : filename including extention (default: saved_file<datetime>.csv)\n",
    "    \n",
    "    Returns\n",
    "      Nothing\n",
    "    '''\n",
    "\n",
    "    filename=check_filename(filename=filename, file_extention='csv')\n",
    "    \n",
    "    # transpose vertical list to horizontal list for CSV file \n",
    "    \n",
    "    with open(filename, 'w', newline='') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        for val in input_list:\n",
    "            wr.writerow(str(val))\n",
    "    myfile.close()\n",
    "    \n",
    "    print('Saved list with < {} > values to: {}'.format(\n",
    "                                                    len(input_list),\n",
    "                                                    filename)\n",
    "         )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing\n",
    "def save_dict_to_json(input_dict={}, filename=''):\n",
    "    '''\n",
    "    Save a list object to JSON file\n",
    "    '''\n",
    "    \n",
    "    filename=check_filename(filename=filename, file_extention='json')\n",
    "\n",
    "    with open(filename, 'w') as fp:\n",
    "        json.dump(input_dict, fp)\n",
    "        \n",
    "    print('Saved list with < {} > key values to: {}'.format(\n",
    "                                                len(input_dict),\n",
    "                                                filename)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing\n",
    "def generate_word_mapping(input_text='', inputfile=''):\n",
    "    '''\n",
    "    Process a (set of) file path(s) to processed_result\n",
    "    '''  \n",
    "    \n",
    "    # Check if all characters are UTF-8 encoded\n",
    "    # Return any errors, line and example if a non UTF-8 character is found, so user can correct it\n",
    "    \n",
    "    # Filter code words out of input_text to only keep variabales; headers and other values that need transalation\n",
    "    # Filter out reservered python words\n",
    "\n",
    "    if inputfile == '':\n",
    "        words_list = input_text.split()\n",
    "    \n",
    "        words_list_NLD = list(dict.fromkeys(words_list))\n",
    "\n",
    "        # save words_list_NLD to csv file\n",
    "        save_list_to_csv(words_list_NLD)\n",
    "\n",
    "        # Let user translate words in words_list_NLD\n",
    "        \n",
    "        print('Please add the translated values for the word_list created,\\n'+\\\n",
    "          'separated by pipe character ( | ) in the created CSV file.\\n')     \n",
    "        print('Please provide path to the updated CSV file.')\n",
    "        inputfile=input()\n",
    "        \n",
    "        translation_dict = read_csv_to_dict(filename=inputfile)\n",
    "    \n",
    "    # Translate words_list_NLD via API service to ENG https://translate.yandex.com/?lang=nl-en&text=onderdeel   \n",
    "\n",
    "    else:\n",
    "        translation_dict = read_csv_to_dict(filename=inputfile)\n",
    "    \n",
    "#     # save translation_dict to json file\n",
    "#     save_dict_to_json(input_dict=translation_dict, filename='')\n",
    "    \n",
    "    return translation_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(filepaths=[], search_words={}):\n",
    "    '''\n",
    "    Process a (set of) file path(s) to processed_result\n",
    "    '''\n",
    "    \n",
    "    for path in filepaths:\n",
    "        \n",
    "        try:\n",
    "#             with open(path, 'r') as file:\n",
    "#                 file.close()\n",
    "\n",
    "            json_data = create_json_data(path)\n",
    "            json_data = process_json_data(json_data, search_words)\n",
    "            save_json_data(json_data, str(path).replace('.ipynb', '_translated.ipynb'))\n",
    "\n",
    "        except OSError:\n",
    "            # handle error here\n",
    "            print('Unable to process file: {}\\n'.format(path))\n",
    "        \n",
    "        processed_result = json_data\n",
    "        \n",
    "    return processed_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start translation script @16:06:03\n",
      "Please enter path to folder where *.ipynb files can be found that need translation\n",
      "C:\\Users\\Maarten\\Documents\\GitHub\\demo-databases\\create_dataframes.ipynb\n",
      "func:'get_path' args:[(), {}] took: 4.0653 sec\n",
      "func:'get_files' args:[('C:\\\\Users\\\\Maarten\\\\Documents\\\\GitHub\\\\demo-databases\\\\create_dataframes.ipynb',), {}] took: 0.0000 sec\n",
      "func:'generate_word_mapping' args:[(), {'input_text': '', 'inputfile': 'translation_input_text.csv'}] took: 0.0010 sec\n",
      "Saved json_data to file: C:\\Users\\Maarten\\Documents\\GitHub\\demo-databases\\create_dataframes_translated.ipynb\n",
      "Finished translation script @16:06:07\n",
      "func:'main' args:[(), {}] took: 4.0713 sec\n"
     ]
    }
   ],
   "source": [
    "inputfile='translation_input_text.csv'\n",
    "\n",
    "\n",
    "@timing\n",
    "def main():\n",
    "    print(\"Start translation script @\"+datetime.now().strftime(\"%H:%M:%S\").upper())\n",
    "    \n",
    "    initial_path = 'C:\\\\Users\\\\Maarten\\\\Documents\\\\GitHub\\\\demo-databases'\n",
    "\n",
    "    initial_path = get_path()\n",
    "    \n",
    "    filepaths = get_files(initial_path)\n",
    "    \n",
    "    translation_dict = generate_word_mapping(input_text='', inputfile=inputfile)\n",
    "\n",
    "    process_files(filepaths=filepaths, search_words=translation_dict)\n",
    "\n",
    "    print(\"Finished translation script @\"+datetime.now().strftime(\"%H:%M:%S\").upper())\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select the .ipynb notebook cells you need for a singel script .py\n",
    "# #   once selected the cells, use SHIFT + M to merge these INPUT cells to a single input cell.\n",
    "# #   Then apply the magic function %writefile [-a] filename\n",
    "\n",
    "# %writefile [-a] 'translate_demo-database_scripts_NLD_2_ENG.py'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
