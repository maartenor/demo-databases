{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import csv\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "from time import time\n",
    "\n",
    "def timing(f):\n",
    "    @wraps(f)\n",
    "    def wrap(*args, **kw):\n",
    "        ts = time()\n",
    "        result = f(*args, **kw)\n",
    "        te = time()\n",
    "        print('func:%r args:[%r, %r] took: %2.4f sec' % \\\n",
    "          (f.__name__, args, kw, te-ts))\n",
    "        return result\n",
    "    return wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing\n",
    "def get_path():\n",
    "    '''\n",
    "    Let user select an initial (folder) path; or provide default PWD\n",
    "    '''\n",
    "    \n",
    "#    initial_path='C:\\\\Users\\\\Maarten\\\\Documents\\\\GitHub\\\\demo-databases'\n",
    "    print('Please enter path to folder where *.ipynb files can be found that need translation')\n",
    "    initial_path=input()\n",
    "    \n",
    "    attempts=0\n",
    "    \n",
    "    while os.path.exists(initial_path) == False: # or attempts <5:\n",
    "        print('Please enter path to folder where *.ipynb files can be found.')\n",
    "        initial_path=input()\n",
    "        attempts+=1\n",
    "        \n",
    "        if not os.path.exists(initial_path):\n",
    "            print('Invalid path provided. Please try again') \n",
    "        else: break\n",
    "\n",
    "        if attempts == 5:\n",
    "            print('To many attempts and invalid paths provided. Stopped.')\n",
    "            initial_path=''\n",
    "            break\n",
    "    \n",
    "    if initial_path == None:\n",
    "        initial_path = pwd()\n",
    "\n",
    "    return initial_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing\n",
    "def get_files(initial_path=''):\n",
    "    '''\n",
    "    Use a initial folder path to create a list of file paths.\n",
    "    \n",
    "    Filters file paths to resulst with only *.IPYNB files/extentions\n",
    "    \n",
    "    Keyword arguments:\n",
    "       initial_path : filename including extention (default: saved_file<datetime>.csv)\n",
    "    \n",
    "    Returns\n",
    "      filepaths : list of pathnames \n",
    "    '''\n",
    "      \n",
    "    base_dir=os.path.realpath(initial_path)+'\\\\'\n",
    "    filepaths=[]\n",
    "    \n",
    "    if os.path.isfile(initial_path):\n",
    "         if str(initial_path).find('.ipynb') > 0:\n",
    "            filepaths=[initial_path]\n",
    "    \n",
    "    elif os.path.isdir(initial_path):\n",
    "            if len(os.listdir(initial_path)) == 0:\n",
    "                print('No valid files found in {}.\\nStopped.\\n\\n'\\\n",
    "                      .format(str(initial_path)))\n",
    "            else:        \n",
    "                for file in os.listdir(initial_path):\n",
    "                    if str(file).find('.ipynb') > 0:\n",
    "                        filepaths.append(base_dir+file)\n",
    "    else: \n",
    "        print('No valid files found in {}.\\nStopped.\\n\\n'\\\n",
    "                      .format(str(initial_path)))\n",
    "    \n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstfile='translate_pepped - Copy - Copy.ipynb'\n",
    "tstfile_out = 'translate_pepped TRANSLATED.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old strategy to parse and split every IPYNB cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from functools import wraps\\n', 'from time import time\\n', '\\n', 'def timing(f):\\n', '    @wraps(f)\\n', '    def wrap(*args, **kw):\\n', '        ts = time()\\n', '        result = f(*args, **kw)\\n', '        te = time()\\n', \"        print('func:%r args:[%r, %r] took: %2.4f sec' % \\\\\\n\", '          (f.__name__, args, kw, te-ts))\\n', '        return result\\n', '    return wrap'] \n",
      "\n",
      "['     '] \n",
      "\n",
      "['woonplaatsen_df = pd.read_csv(\\'Woonplaatsen_in_Nederland_2018_07042020_210926.csv\\', sep=\\'\";\"\\', skiprows=3, encoding=\\'UTF-8\\')\\n', \"# Added , encoding='UTF-8' to prevent value 'SÃºdwest-FryslÃ¢n' in CSV being loaded as 'SÃƒÂºdwest-FryslÃƒÂ¢n'\\n\", '\\n', 'woonplaatsen_df = woonplaatsen_df[1:]\\n', 'new_column_names = list(woonplaatsen_df.columns)\\n', \"new_column_names[0]='Woonplaats'\\n\", 'woonplaatsen_df.columns = new_column_names\\n', ' \\n', 'woonplaatsen_df[\\'Woonplaats\\'] = woonplaatsen_df[\\'Woonplaats\\'].apply(lambda x: str(x).replace(\\'\"\\', \\'\\') )\\n', 'woonplaatsen_df[\\'Landsdeel|Code\"\\'] = woonplaatsen_df[\\'Landsdeel|Code\"\\'].apply(lambda x: str(x).replace(\\'\"\\', \\'\\') )\\n', '\\n', '\\n', '# Take small sample of woonplaatsen_df and create new (incorrect) indexes (based on klant_df)\\n', 'woonplaatsen_df=woonplaatsen_df.sample(len(klant_df))\\n', 'woonplaatsen_df.reset_index(inplace=True)\\n', \"woonplaatsen_df.index=klant_df['klant_woonplaats']\\n\", '\\n', '\\n', 'if show_intermediate_results == True:\\n', '    \\n', '    print(woonplaatsen_df.head(10) )'] \n",
      "\n",
      "['@timing\\n', 'def get_path():\\n', \"    '''\\n\", '    Let user select an initial (folder) path; or provide default PWD\\n', \"    '''\\n\", '    \\n', \"    initial_path='wherever we are now'\\n\", '    \\n', '    if initial_path == None:\\n', '        initial_path = pwd()\\n', '\\n', '    return initial_path'] \n",
      "\n",
      "['@timing\\n', \"def get_files(initial_path=''):\\n\", \"    '''\\n\", '    Use a initial folder path to create a list of file paths.\\n', \"    '''\\n\", '    return filepaths'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(tstfile, 'r') as file:\n",
    "    nb = json.load(file)\n",
    "\n",
    "file.close()\n",
    "            \n",
    "# nb['cells']\n",
    "\n",
    "i=0\n",
    "#for cel in nb['cells']:\n",
    "\n",
    "while i <6:\n",
    "    i+=1\n",
    "    if nb['cells'][i]['cell_type'] == 'code':\n",
    "        if len(nb['cells'][i]['source']) > 0:\n",
    "            print(nb['cells'][i]['source'], '\\n')\n",
    "            nb['cells'][i]['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['woonplaatsen_df', '=', \"pd.read_csv('Woonplaatsen_in_Nederland_2018_07042020_210926.csv',\", 'sep=\\'\";\"\\',', 'skiprows=3,', \"encoding='UTF-8')\", '#', 'Added', ',', \"encoding='UTF-8'\", 'to', 'prevent', 'value', \"'SÃºdwest-FryslÃ¢n'\", 'in', 'CSV', 'being', 'loaded', 'as', \"'SÃƒÂºdwest-FryslÃƒÂ¢n'\", 'woonplaatsen_df', '=', 'woonplaatsen_df[1:]', 'new_column_names', '=', 'list(woonplaatsen_df.columns)', \"new_column_names[0]='Woonplaats'\", 'woonplaatsen_df.columns', '=', 'new_column_names', \"woonplaatsen_df['Woonplaats']\", '=', \"woonplaatsen_df['Woonplaats'].apply(lambda\", 'x:', 'str(x).replace(\\'\"\\',', \"'')\", ')', 'woonplaatsen_df[\\'Landsdeel|Code\"\\']', '=', 'woonplaatsen_df[\\'Landsdeel|Code\"\\'].apply(lambda', 'x:', 'str(x).replace(\\'\"\\',', \"'')\", ')', '#', 'Take', 'small', 'sample', 'of', 'woonplaatsen_df', 'and', 'create', 'new', '(incorrect)', 'indexes', '(based', 'on', 'klant_df)', 'woonplaatsen_df=woonplaatsen_df.sample(len(klant_df))', 'woonplaatsen_df.reset_index(inplace=True)', \"woonplaatsen_df.index=klant_df['klant_woonplaats']\", 'if', 'show_intermediate_results', '==', 'True:', 'print(woonplaatsen_df.head(10)', ')']\n",
      "\n",
      "{'CSV', 'prevent', 'and', 'klant_df)', \"encoding='UTF-8')\", '#', \"pd.read_csv('Woonplaatsen_in_Nederland_2018_07042020_210926.csv',\", 'sample', \"'SÃƒÂºdwest-FryslÃƒÂ¢n'\", \"new_column_names[0]='Woonplaats'\", 'indexes', 'if', 'woonplaatsen_df=woonplaatsen_df.sample(len(klant_df))', 'woonplaatsen_df', 'value', 'new_column_names', ')', 'create', \"'SÃºdwest-FryslÃ¢n'\", 'small', \"encoding='UTF-8'\", 'Added', 'show_intermediate_results', 'print(woonplaatsen_df.head(10)', \"woonplaatsen_df['Woonplaats']\", 'Take', \"woonplaatsen_df.index=klant_df['klant_woonplaats']\", 'woonplaatsen_df[\\'Landsdeel|Code\"\\']', 'to', 'new', 'x:', 'list(woonplaatsen_df.columns)', \"'')\", 'skiprows=3,', ',', 'in', '=', '==', 'sep=\\'\";\"\\',', 'woonplaatsen_df[1:]', 'woonplaatsen_df.reset_index(inplace=True)', 'woonplaatsen_df[\\'Landsdeel|Code\"\\'].apply(lambda', '(incorrect)', 'as', 'being', 'on', 'loaded', \"woonplaatsen_df['Woonplaats'].apply(lambda\", '(based', 'woonplaatsen_df.columns', 'True:', 'str(x).replace(\\'\"\\',', 'of'}\n"
     ]
    }
   ],
   "source": [
    "val_list=[]\n",
    "for val in cell_val:\n",
    "    splitted=val.split()\n",
    "\n",
    "    for value in splitted:\n",
    "        value=value.split('[')\n",
    "        splitted[]\n",
    "#         if value not in exception_from_translation:\n",
    "#             val_list+=value\n",
    "    val_list+=splitted\n",
    "\n",
    "print(val_list)\n",
    "print()\n",
    "print(set(val_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in ['from datetime import datetime\\n', 'import csv\\n', 'import json']:\n",
    "    if val == 'import csv\\n':\n",
    "        print(list.index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  New strategy. String replacement in JSON object using translation dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json_data(filename):\n",
    "    \n",
    "    with open(tstfile, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "    \n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json_data(json_data, filename):\n",
    "    \n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(json_data, file, indent=2)\n",
    "    \n",
    "    return print('Saved json_data to file: {}'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_words={'import':'IMPORT_THE_WORLD',\n",
    "            'woonplaatsen_df':'__RESIDENCE__DF'}\n",
    "search_words_key=list(search_words.keys())\n",
    "#search_words_value=search_words[search_words_key]\n",
    "\n",
    "\n",
    "with open(tstfile, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "def process_json_data(json_data_object, search_words={}):\n",
    "    \n",
    "    for cell in json_data['cells']:\n",
    "#          if cell['cell_type'] in ['code']:\n",
    "#                 print(cell['source'])\n",
    "#                 for val in cell['source']:\n",
    "#                     if val.find(search_words_key[0]) > 0:\n",
    "#                         cell['source'][cell['source'].index(val)] = val.replace(search_words_key[0], search_words_value)\n",
    "#                 print('--> ',cell['source'],'\\nn')\n",
    "\n",
    "         if cell['cell_type'] in ['code']:\n",
    "#                print(cell['source'])\n",
    "                for search_words_key in list(search_words.keys()):\n",
    "                    for val in cell['source']:\n",
    "                        if str.lower(val).find(str.lower(search_words_key)) >= 0:\n",
    "                            cell['source'][cell['source'].index(val)] = val.replace(search_words_key, search_words[search_words_key])\n",
    "#                        print('\\n--> ',val,'\\n',(str.lower(val).find(str.lower(search_words_key)) >= 0),'\\n\\n')\n",
    "#                print('\\n--> ',cell['source'],'\\n\\n')\n",
    "\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved json_data to file: translate_pepped TRANSLATED.ipynb\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'translate_pepped - Copy - Copy.ipynb'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(filepaths=[]):\n",
    "    '''\n",
    "    Process a (set of) file path(s) to processed_result\n",
    "    '''\n",
    "    \n",
    "    for path in filepaths:\n",
    "        \n",
    "        try:\n",
    "            with open(path, 'r') as file:\n",
    "                for row in file:\n",
    "                    print(row)\n",
    "            file.close()\n",
    "\n",
    "        except OSError:\n",
    "            # handle error here\n",
    "            print('Unable to process file: {}\\n'.format(path))\n",
    "        \n",
    "        processed_result = \n",
    "        processed_result\n",
    "        \n",
    "    return processed_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing\n",
    "def generate_word_mapping(input_text):\n",
    "    '''\n",
    "    Process a (set of) file path(s) to processed_result\n",
    "    '''  \n",
    "    \n",
    "    # Check if all characters are UTF-8 encoded\n",
    "    # Return any errors, line and example if a non UTF-8 character is found, so user can correct it\n",
    "    \n",
    "    # Filter code words out of input_text to only keep variabales; headers and other values that need transalation\n",
    "    # Filter out reservered python words\n",
    "    \n",
    "    words_list = input_text.split()\n",
    "    \n",
    "    words_list_NLD = list(dict.fromkeys(words_list))\n",
    "    \n",
    "    # save words_list_NLD to csv file\n",
    "    save_list_to_csv(words_list_NLD):\n",
    "    \n",
    "    \n",
    "    # Translate words_list_NLD via API service to ENG https://translate.yandex.com/?lang=nl-en&text=onderdeel\n",
    "    \n",
    "    # Let user translate words in words_list_NLD\n",
    "    \n",
    "    # save translation_dict to json file\n",
    "    save_dict_to_json(input_dict=translation_dict, filename='')\n",
    "    \n",
    "    return translation_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing\n",
    "def save_list_to_csv(input_list=[], filename=''):\n",
    "    '''\n",
    "    Save a list object to an CSV file\n",
    "    \n",
    "    Keyword arguments:\n",
    "      input_list : list of values to write in .CSV file\n",
    "      filename : filename including extention (default: saved_file<datetime>.csv)\n",
    "    \n",
    "    Returns\n",
    "      Nothing\n",
    "    '''\n",
    "\n",
    "    filename=check_filename(filename=filename, file_extention='csv')\n",
    "    \n",
    "    # transpose vertical list to horizontal list for CSV file \n",
    "    \n",
    "    with open(filename, 'w', newline='') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        for val in input_list:\n",
    "            wr.writerow(str(val))\n",
    "    myfile.close()\n",
    "    \n",
    "    print('Saved list with < {} > values to: {}'.format(\n",
    "                                                    len(input_list),\n",
    "                                                    filename)\n",
    "         )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing\n",
    "def save_dict_to_json(input_dict={}, filename=''):\n",
    "    '''\n",
    "    Save a list object to JSON file\n",
    "    '''\n",
    "    \n",
    "    filename=check_filename(filename=filename, file_extention='json')\n",
    "\n",
    "    with open(filename, 'w') as fp:\n",
    "        json.dump(input_dict, fp)\n",
    "        \n",
    "    print('Saved list with < {} > key values to: {}'.format(\n",
    "                                                len(input_dict),\n",
    "                                                filename)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing\n",
    "def check_filename(filename, file_extention=''):\n",
    "    '''\n",
    "    Check a filename (str) for several minimum requirements and \n",
    "       add the file_extention (str) w/o period character '.' to it.\n",
    "    \n",
    "    Keyword arguments:\n",
    "      filename : filename excluding extention (default: saved_file<datetime>)\n",
    "      file_extention : requested file extention (default: .csv)  \n",
    "    \n",
    "    Return filename (string)\n",
    "    '''\n",
    "\n",
    "    if type(filename) is not str:\n",
    "        filename=str(filename)\n",
    "    \n",
    "    if len(filename) == 0:\n",
    "        filename='saved_file'+datetime.now().strftime(\"%d-%b-%Y_%H-%M\").upper()\n",
    "    \n",
    "    if str(filename).find(file_extention)<0:\n",
    "        if str(file_extention).find('.')<0:\n",
    "            file_extention='.'+file_extention\n",
    "        if file_extention == '.' or len(file_extention)<4:\n",
    "            file_extention = '.csv'\n",
    "        filename=filename+file_extention\n",
    "    \n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@timing\n",
    "def main():\n",
    "    print(\"Start translation script @\"+datetime.now().strftime(\"%H:%M:%S\").upper())\n",
    "    \n",
    "    initial_path='C:\\\\Users\\\\Maarten\\\\Documents\\\\GitHub\\\\demo-databases'\n",
    "\n",
    "    initial_path=get_path()\n",
    "    \n",
    "    get_files(initial_path)\n",
    "    \n",
    "\n",
    "#     json_data = create_json_data(tstfile)\n",
    "#     json_data = process_json_data(json_data, search_word)\n",
    "#     save_json_data(json_data, tstfile_out)\n",
    "\n",
    "    print(\"Finished translation script @\"+datetime.now().strftime(\"%H:%M:%S\").upper())\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select the .ipynb notebook cells you need for a singel script .py\n",
    "# #   once selected the cells, use SHIFT + M to merge these INPUT cells to a single input cell.\n",
    "# #   Then apply the magic function %writefile [-a] filename\n",
    "\n",
    "# %writefile [-a] 'translate_demo-database_scripts_NLD_2_ENG.py'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
